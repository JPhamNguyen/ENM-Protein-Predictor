"""Developed by: Matthew Findlay 2017
Modified by: Joseph Pham 2021

This module contains the validation_metrics class that handles calculating, storing, and formatting all of the metrics
for evaluating the performance of the model.
"""
from sklearn import metrics
import statistics as stat
import pandas as pd
import numpy as np


class validation_metrics(object):
    """Several statistical tests used to validate the model's predictive power
    Args: None
    Attributes:
        :_true_results (array of ints): The true test values
        :_predicted_results (array of floats): The predicted values generated by the model
        :_sorted_predicted_results (pandas DataFrame): This dataframe will contain all of the final information
        and statistics to be outputted to a CSV file
        :_filters (pandas DataFrame): Will contain necessary data and protein-particle conditions to sort by when
        calculating, storing, and formatting model statistics information
        :_mse (array of floats): Contains mse error score values
        :_rmse (array of floats): Contains rmse error score values
        :_mae (array of floats): Contains mae error score values
        :_mape (array of floats): Contains mape error score values
    """
    def __init__(self):
        self._true_results = None
        self._predicted_results = None
        self._filters = None
        self._sorted_predicted_results = pd.DataFrame(columns=['Accession Number', 'Particle Size', 'Particle Charge',
                                                               'Solvent Conditions', 'Average Predicted Value', 'True Value'])
        self._feature_importances = {}
        self._mse = []
        self._rmse = []
        self._mae = []
        self._mape = []

    def set_parameters(self, true_results, predicted_results, accession_numbers, conditions):
        """During the pipeline, set temporary objects 'true_results' and 'predicted results' to calculate error metrics
        and other desired information
        Args:
            :param: true_results (ndarray of floats): array containing the true targets to compare prediction values against
            :param: predicted_results (ndarray of floats): contains predicted targets for prediction on X_test
            :param: accession_numbers (pandas Series): contains Accession Numbers to use for filtering predicted values
            :param: conditions (pandas DataFrame): contains protein particle conditions that will be used to filter the
            predicted values
        Returns: None
        """
        self._true_results = pd.DataFrame(true_results, columns=['True Value'], index=accession_numbers)
        self._predicted_results = predicted_results.tolist()

        # set the categories for filtering predicted values
        self._filters = conditions.copy(deep=True)
        self._filters.insert(0, 'Accession Numbers', accession_numbers)
        self._filters.insert(len(self._filters.columns), 'Predicted Value', predicted_results)
        self._filters.insert(len(self._filters.columns), 'True Value', true_results)
        self._filters.reset_index(inplace=True)
        self._filters.drop(labels='index', axis=1, inplace=True)

    def update_predictions(self):
        """Update and insert predicted values into _sorted_prediction_results after filtering by accession number and
        protein-particle conditions
        Args, Returns: None
        """
        # obtain specific conditions for each protein-particle pair
        solvent_conditions = ['Solvent Cysteine Concentration_0.1', 'Solvent NaCl Concentration_0.8',
                              'Solvent NaCl Concentration_3.0']

        # use intermediate dataframe to initialize sorted_predicted_results
        if self._sorted_predicted_results.empty:
            intermediate_df = pd.DataFrame()

        new_values = []
        for idx in self._filters.index:
            accession_number = self._filters.at[idx, 'Accession Numbers']
            predicted_value = self._filters.at[idx, 'Predicted Value']
            true_value = self._filters.at[idx, 'True Value']

            # filter through protein-particle conditions
            if self._filters.at[idx, 'Particle Size_10'] == 1.0:
                particle_size = '10 nm'
            else:
                particle_size = '100 nm'
            if self._filters.at[idx, 'Particle Charge_0'] == 1.0:
                particle_charge = 'Negative'
            else:
                particle_charge = 'Positive'

            solvent = '10 mM NaPi pH 7.4'
            for sol in solvent_conditions:
                if self._filters.at[idx, sol] == 1.0:
                    if sol == 'Solvent Cysteine Concentration_0.1':
                        solvent += ' + 0.1 mM cys'
                    elif sol == 'Solvent NaCl Concentration_0.8':
                        solvent += ' + 0.8 mM NaCl'
                    else:
                        solvent += ' + 3.0 mM NaCl'

            # If the specific protein-particle pair's conditions exist in _sorted_prediction_results
            if(self._sorted_predicted_results['Accession Number'] == accession_number).any() and \
                    (self._sorted_predicted_results['Particle Size'] == particle_size).any() and \
                    (self._sorted_predicted_results['Particle Charge'] == particle_charge).any() and \
                    (self._sorted_predicted_results['Solvent Conditions'] == solvent).any() and \
                    (self._sorted_predicted_results['True Value'] == true_value).any():

                a_num_filter = self._sorted_predicted_results.index[self._sorted_predicted_results['Accession Number']
                                                                    == accession_number].tolist()
                p_size_filter = self._sorted_predicted_results.index[self._sorted_predicted_results['Particle Size']
                                                                     == particle_size].tolist()
                p_charge_filter = self._sorted_predicted_results.index[self._sorted_predicted_results['Particle Charge']
                                                                       == particle_charge].tolist()
                solvent_filter = self._sorted_predicted_results.index[self._sorted_predicted_results
                                                                      ['Solvent Conditions'] == solvent].tolist()
                true_val_filter = self._sorted_predicted_results.index[self._sorted_predicted_results
                                                                      ['True Value'] == true_value].tolist()
                row_index = list(set.intersection(*map(set, [a_num_filter, p_size_filter, p_charge_filter,
                                                             solvent_filter, true_val_filter])))

                # Sometimes a strange identification fault occurs
                if not row_index:
                    new_values.append([accession_number, particle_size, particle_charge, solvent, [predicted_value],
                                       true_value])
                else:
                    # Append to existing predicted values in the DataFrame
                    self._sorted_predicted_results.at[row_index[0], 'Average Predicted Value'].append(predicted_value)
            else:
                # store sorted prediction results and concatenate them to the DataFrame after
                new_values.append([accession_number, particle_size, particle_charge, solvent, [predicted_value],
                                   true_value])

        # append new protein-particle pairs and their conditions + values to the final sorted predictions
        new_df = pd.DataFrame(data=new_values, columns=['Accession Number', 'Particle Size', 'Particle Charge',
                                                        'Solvent Conditions', 'Average Predicted Value', 'True Value'])

        if self._sorted_predicted_results.empty:
            self._sorted_predicted_results = pd.concat([intermediate_df, new_df])
        else:
            self._sorted_predicted_results = pd.concat([self._sorted_predicted_results, new_df], ignore_index=True)

    def update_feature_importances(self, optimal_features, scores):
        """Update the feature_importance scores and store into a dictionary
        Args:
            :param: optimal_features (pandas Series): contains the names of optimal features inputted into model
            :param: scores (narray of floats): contains the Gini importance scores for each optimal feature
        Returns: None
        """
        for idx, feat in enumerate(optimal_features):
            self._feature_importances.setdefault(feat, []).append(scores[idx])

    def calculate_error_metrics(self):
        """Calculate various error metric values like MSE (Mean Squared Errors) and RMSE (Root Mean Squared Error)
        and store them into error-metric-specific lists
        Args, Returns: None
        """
        # as the model goes through the pipeline, store each individual error score in each respective list
        self._mse.append(metrics.mean_squared_error(y_true=self._true_results, y_pred=self._predicted_results))
        self._rmse.append(metrics.mean_squared_error(y_true=self._true_results, y_pred=self._predicted_results, squared=False))
        self._mae.append(metrics.mean_absolute_error(y_true=self._true_results, y_pred=self._predicted_results))
        self._mape.append(metrics.mean_absolute_percentage_error(y_true=self._true_results, y_pred=self._predicted_results))

    def calculate_final_metrics(self):
        """After the pipeline has run through all of its iterations, calculate final metrics and return them either as
        a text or CSV file
        Args: None
        Returns:
            :return: avg_errs (dict): a dictionary containing key-value pairs in the form {'type of error': error value}
            :return: sorted_predicted_results (pandas DataFrame): contains several statistics on the predicted value
            :return: feature_importances (dict): dictionary containing the average of the Gini importances for each
            optimal feature
        """
        # calculate the average of all error metrics
        keys = ['average MSE', 'average RMSE', 'average MAE', 'average MAPE']
        avg_errs_vals = [stat.mean(self._mse), stat.mean(self._rmse), stat.mean(self._mae),
                         stat.mean(self._mape)]

        # calculate min, max, standard deviation, mean average predicted value, and % Error Difference
        stats_columns = ['% Error Difference', 'Min', 'Max', 'Standard Deviation']
        for col in stats_columns:
            self._sorted_predicted_results[col] = np.nan

        for idx in self._sorted_predicted_results.index:
            self._sorted_predicted_results.at[idx, 'Min'] = min(self._sorted_predicted_results.at[idx, 'Average Predicted Value'])
            self._sorted_predicted_results.at[idx, 'Max'] = max(self._sorted_predicted_results.at[idx, 'Average Predicted Value'])

            # if there aren't enough values to calculate standard deviation
            if len(self._sorted_predicted_results.at[idx, 'Average Predicted Value']) > 1:
                self._sorted_predicted_results.at[idx, 'Standard Deviation'] = stat.stdev(
                    self._sorted_predicted_results.at[idx, 'Average Predicted Value'])
            else:
                self._sorted_predicted_results.at[idx, 'Standard Deviation'] = 0

            self._sorted_predicted_results.at[idx, 'Average Predicted Value'] = stat.mean(
                self._sorted_predicted_results.at[idx, 'Average Predicted Value'])

            avg_val = self._sorted_predicted_results.at[idx, 'Average Predicted Value']
            true_val = self._sorted_predicted_results.at[idx, 'True Value']
            self._sorted_predicted_results.at[idx, '% Error Difference'] = (abs(avg_val - true_val))/true_val

        # calculate average + standard deviation of feature importances
        stddev = {}
        for feat in self._feature_importances.keys():
            stddev[feat] = stat.stdev((self._feature_importances[feat]))
            self._feature_importances[feat] = stat.mean(self._feature_importances[feat])

        return dict(zip(keys, avg_errs_vals)), self._sorted_predicted_results, self._feature_importances, stddev

