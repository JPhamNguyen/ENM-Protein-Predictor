"""Developed by: Matthew Findlay 2017
Modified by: Joseph Pham 2021

This module calculates and stores error metrics and other useful statistics for measuring model performance
"""

from sklearn import metrics
import statistics as stat
import sys
import pandas as pd


class validation_metrics(object):
    """Several statistical tests used to validate the models predictive power

    Args:
        :param: true_results (array of ints): The true testing values
        :param: predicted_results (array of floats): The predicted probabilities
        generated by the model
        :param: predicted_results_by_acession_number (dict of floats): dictionary that contains accession-number-
        specific values
    Attributes:
        :true_results (array of ints): The true testing values
        :predicted_results (array of floats): The predicted probabilities
        generated by the model
        : mse (array of floats): The mse values
        :rmse (array of floats): The rmse values
        :mae (array of floats): The mae values
        : mape (array of floats): The mape values
    """
    def __init__(self):
        self._true_results = None
        self._predicted_results = None
        self._filters = None
        self._sorted_predicted_results = {}
        self._feature_importances = {}
        self._mse = []
        self._rmse = []
        self._mae = []
        self._mape = []

    def set_parameters(self, true_results, predicted_results, accession_numbers, conditions):
        """During the pipeline, set temporary true_results and predicted results to calculate error metrics and
        other desired information
        Args:
            :param: true_results (ndarray of floats): array containing the true targets to compare prediction values against
            :param: predicted_results (ndarray of floats): contains predicted targets for prediction on X_test
            :param: accession_numbers (pandas Series): contains Accession Numbers to use for filtering predicted values
            :param: conditions (pandas DataFrame): contains protein particle conditions that will be used to further
            filter the predicted values
        Returns: None
        """
        self._true_results = pd.DataFrame(true_results, columns=['True Value'], index=accession_numbers)
        self._predicted_results = predicted_results.tolist()

        # set the categories for filtering predicted values
        self._filters = conditions
        self._filters.insert(0, 'Accession Numbers', accession_numbers)
        self._filters.insert(len(self._filters.columns), 'Predicted Values', predicted_results)
        self._filters.reset_index(inplace=True)
        self._filters.drop(labels='index', axis=1, inplace=True)
        print(self._filters['Particle Charge_0'])

    def update_feature_importances(self, optimal_features, scores):
        """Update the feature_importance scores and store into a dictionary
        Args:
            :param: optimal_features (pandas Series): contains the names of optimal features inputted into model
            :param: scores (narray of floats): contains the Gini importance scores for each optimal feature
        Returns: None
        """
        for idx, feat in enumerate(optimal_features):
            self._feature_importances.setdefault(feat, []).append(scores[idx])

    def update_predictions(self):
        """Update predicted values by accession number
        Args:
            :param: accession_numbers (pandas Series): Series containing the tested particle protein pairs' Accession Numbers
            :param: y_pred (array of floats): nparray containing the predicted regression targets for X_test
        Returns: None
        """
        accession_number = ''
        particle_size = '10 nm'
        particle_charge = 'Negative'
        solvent = ''
        solvent_conditions = ['Solvent Cysteine Concentration_0.0', 'Solvent Cysteine Concentration_0.1',
                              'Solvent NaCl Concentration_0.0', 'Solvent NaCl Concentration_0.8',
                              'Solvent NaCl Concentration_3.0']

        # Note: have to check conditions because they reproduce SettingWithCopyWarning
        for idx in self._filters.index:
            accession_number = self._filters.at[idx, 'Accession Numbers']
            if self._filters.at[idx, 'Particle Size_10'] == 0.0:
                particle_size = '100 nm'
            if self._filters.at[idx, 'Particle Charge_0'] == 0.0:
                particle_charge = 'Positive'
            for sol in solvent_conditions:
                if self._filters.at[idx, sol] == 1.0:
                    solvent = sol

            self._sorted_predicted_results.setdefault(accession_number, {}).setdefault(particle_size, {}).\
                setdefault(particle_charge, {}).setdefault(solvent, {}).setdefault('Average Predicted Value', []).\
                append(self._filters.at[idx, 'Predicted Values'])

    def calculate_error_metrics(self):
        """Calculate various error metric values like MSE and RMSE, and store them into error-metric-specific lists
        Args, Returns: None
        """
        # as the model goes through the pipeline, store each individual error score in each respective list
        self._mse.append(metrics.mean_squared_error(y_true=self._true_results, y_pred=self._predicted_results))
        self._rmse.append(metrics.mean_squared_error(y_true=self._true_results, y_pred=self._predicted_results, squared=False))
        self._mae.append(metrics.mean_absolute_error(y_true=self._true_results, y_pred=self._predicted_results))
        self._mape.append(metrics.mean_absolute_percentage_error(y_true=self._true_results, y_pred=self._predicted_results))

    def calculate_final_metrics(self):
        """After the pipeline has been run for 'x' amount of times, calculate final metrics and return them as a dictionary
        Args: None
        Returns:
            :return: avg_errs (dict): a dictionary containing key-value pairs in the form {'type of error': error value}
            :return: sorted_predicted_results: dictionary containing the average of each accession number-predicted pair
            :return: feature_importances: dictionary containing the average of the Gini importances for each optimal feature
        """
        # calculate the average of all error metrics
        keys = ['average MSE', 'average RMSE', 'average MAE', 'average MAPE']
        avg_errs_vals = [stat.mean(self._mse), stat.mean(self._rmse), stat.mean(self._mae),
                         stat.mean(self._mape)]

        # Need to grab the dictionary keys in order to reach the right 'Average Predicted Value' array
        # After grabbing the array, I need to then access that path again
        # for a_num in self._sorted_predicted_results.keys():
        #    print(a_num)

        # sys.exit(0)

        # calculate average of feature importances
        for feat in self._feature_importances.keys():
            self._feature_importances[feat] = stat.mean(self._feature_importances[feat])

        return dict(zip(keys, avg_errs_vals)), self._sorted_predicted_results, self._feature_importances


